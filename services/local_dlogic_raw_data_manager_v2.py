#!/usr/bin/env python3
"""
åœ°æ–¹ç«¶é¦¬ç‰ˆD-Logicç”Ÿãƒ‡ãƒ¼ã‚¿ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ V2
å®Œå…¨ã«ç‹¬ç«‹ã—ãŸå®Ÿè£…ï¼ˆè¦ªã‚¯ãƒ©ã‚¹ã‚’ç¶™æ‰¿ã—ãªã„ï¼‰
"""
import json
import os
import logging
import threading
import time
from collections import OrderedDict
import requests
from typing import Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class LocalDLogicRawDataManagerV2:
    """åœ°æ–¹ç«¶é¦¬ç‰ˆD-Logicç”Ÿãƒ‡ãƒ¼ã‚¿ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ï¼ˆç‹¬ç«‹ç‰ˆï¼‰"""
    
    def __init__(self):
        """åˆæœŸåŒ–ï¼šåœ°æ–¹ç«¶é¦¬ç‰ˆå°‚ç”¨"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆRenderã§ã¯/tmpã‚’ä½¿ç”¨ï¼‰
        base_dir = os.path.join(os.path.dirname(__file__), '..', 'data')
        if os.environ.get('RENDER'):
            # Renderã§ã¯æ›¸ãè¾¼ã¿å¯èƒ½ãª/tmpãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½¿ç”¨
            base_dir = '/tmp'

        self.knowledge_file = os.path.join(base_dir, 'local_dlogic_raw_knowledge_v2.json')
        self.cache_dir = os.path.join(base_dir, 'local_dlogic_cache')
        self.index_file = os.path.join(self.cache_dir, 'index.json')
        self._horse_index: Dict[str, Dict[str, str]] = {}
        self._meta_info: Dict[str, Any] = {}
        self._shard_cache: "OrderedDict[str, Dict[str, Any]]" = OrderedDict()
        self._shard_lock = threading.Lock()
        self._max_shard_cache = int(os.environ.get("LOCAL_DLOGIC_SHARD_CACHE", "6"))
        self._shard_size = int(os.environ.get("LOCAL_DLOGIC_SHARD_SIZE", "750"))
        self._download_timeout = int(os.environ.get("LOCAL_DLOGIC_DOWNLOAD_TIMEOUT", "300"))
        
        # CDN URL
        self.cdn_url = "https://pub-059afaafefa84116b57d57e0a72b81bd.r2.dev/nankan_unified_knowledge_20250907.json"
        
        logger.info("ğŸ‡ åœ°æ–¹ç«¶é¦¬ç‰ˆD-Logicãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼V2åˆæœŸåŒ–: cache=%s", self.knowledge_file)

        # ãƒ­ãƒ¼ãƒ‰åˆ¶å¾¡
        self._knowledge_data: Optional[Dict[str, Any]] = None
        self._load_lock = threading.Lock()
        self._last_loaded_at: Optional[datetime] = None

        # è¨ˆç®—ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ¶å¾¡ï¼ˆJRAç‰ˆã¨åŒç­‰ã®ä»•çµ„ã¿ï¼‰
        self._calculation_cache: Dict[str, Dict[str, Any]] = {}
        self._cache_lock = threading.Lock()
        self._cache_hits: int = 0
        self._cache_misses: int = 0
        self._cache_log_interval: int = 20
        self._max_cache_size: int = int(os.environ.get("LOCAL_DLOGIC_CACHE_SIZE", "500"))
    
    def get_total_horses(self) -> int:
        """ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å„ªå…ˆã—ã¦ç·é¦¬æ•°ã‚’å–å¾—ï¼ˆãƒ•ãƒ«ãƒ­ãƒ¼ãƒ‰ã‚’å›é¿ï¼‰"""
        if self._horse_index:
            return len(self._horse_index)

        if os.path.exists(self.index_file):
            if self._load_index():
                return len(self._horse_index)

        if self._knowledge_data and 'horses' in self._knowledge_data:
            return len(self._knowledge_data.get('horses', {}))

        return 0

    def get_sample_horses(self, limit: int = 20) -> list:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ—ãƒªã‚¦ã‚©ãƒ¼ãƒ ç”¨ã«é¦¬åã‚µãƒ³ãƒ—ãƒ«ã‚’å–å¾—"""
        if limit <= 0:
            return []

        if self._horse_index or self._load_index():
            return list(self._horse_index.keys())[:limit]

        horses = self._knowledge_data.get('horses', {}) if self._knowledge_data else {}
        return list(horses.keys())[:limit]

    def get_shard_cache_stats(self) -> Dict[str, Any]:
        """ã‚·ãƒ£ãƒ¼ãƒ‰ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®åˆ©ç”¨çŠ¶æ³ã‚’å–å¾—"""
        with self._shard_lock:
            return {
                "loaded_shards": len(self._shard_cache),
                "max_cached_shards": self._max_shard_cache,
                "cached_horses_estimate": sum(len(shard.keys()) for shard in self._shard_cache.values()),
                "index_loaded": bool(self._horse_index),
                "has_full_knowledge": self._knowledge_data is not None,
                "shard_directory_exists": os.path.exists(self.cache_dir)
            }

    def get_calculation_cache_stats(self) -> Dict[str, Any]:
        """è¨ˆç®—ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’å–å¾—"""
        with self._cache_lock:
            total_requests = self._cache_hits + self._cache_misses
            hit_rate = (self._cache_hits / total_requests) * 100 if total_requests else 0.0
            return {
                "entries": len(self._calculation_cache),
                "max_entries": self._max_cache_size,
                "hits": self._cache_hits,
                "misses": self._cache_misses,
                "hit_rate": round(hit_rate, 2)
            }

    def get_diagnostics(self) -> Dict[str, Any]:
        """ç›£è¦–ç”¨ã®è¨ºæ–­æƒ…å ±ã‚’è¿”ã™"""
        shard_stats = self.get_shard_cache_stats()
        cache_stats = self.get_calculation_cache_stats()
        return {
            "total_horses": self.get_total_horses(),
            "index_loaded": shard_stats["index_loaded"],
            "loaded_shards": shard_stats["loaded_shards"],
            "max_cached_shards": shard_stats["max_cached_shards"],
            "cached_horses_estimate": shard_stats["cached_horses_estimate"],
            "calculation_cache": cache_stats,
            "knowledge_loaded": shard_stats["has_full_knowledge"],
            "shard_dir_exists": shard_stats["shard_directory_exists"],
            "last_loaded_at": self._last_loaded_at.isoformat() if self._last_loaded_at else None
        }

    def _load_knowledge(self) -> Dict[str, Any]:
        """ãƒŠãƒ¬ãƒƒã‚¸ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿"""
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹å ´åˆ
        if os.path.exists(self.knowledge_file):
            try:
                with open(self.knowledge_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                if isinstance(data, dict) and 'horses' in data:
                    horse_count = len(data['horses'])
                    logger.info("ğŸ“‚ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰èª­ã¿è¾¼ã¿ (%sé ­)", horse_count)
                    self._save_sharded_cache(data)
                    return data

                logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹é€ ãŒä¸æ­£ã®ãŸã‚å†å–å¾—ã—ã¾ã™")
            except Exception as e:
                logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚­ãƒ£ãƒƒã‚·ãƒ¥èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ (%s)", e)
        
        # CDNã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        return self._download_from_cdn()
    
    def _download_from_cdn(self) -> Dict[str, Any]:
        """CDNã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰"""
        try:
            logger.info("ğŸ“¥ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: CDNã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹ (%s)", self.cdn_url)
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡åŒ–ï¼‰
            response = requests.get(self.cdn_url, stream=True, timeout=(10, self._download_timeout))
            
            if response.status_code == 200:
                # ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚µã‚¤ã‚ºã‚’ç¢ºèª
                content_length = response.headers.get('content-length')
                if content_length:
                    logger.info("ğŸ“¦ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º %.1fMB", int(content_length) / 1024 / 1024)
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã§å†…å®¹ã‚’å–å¾—
                content = b''
                downloaded = 0
                chunk_size = 1024 * 1024  # 1MB chunks
                start_time = time.monotonic()
                
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        content += chunk
                        downloaded += len(chunk)
                        if content_length and downloaded % (10 * chunk_size) == 0:
                            progress = (downloaded / int(content_length)) * 100
                            logger.debug("ğŸ“¥ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ— %.1f%%", progress)
                        if time.monotonic() - start_time > self._download_timeout:
                            raise requests.exceptions.Timeout("Streaming download exceeded timeout")
                
                logger.info("ğŸ”„ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: JSONãƒ‘ãƒ¼ã‚¹ä¸­")
                data = json.loads(content.decode('utf-8'))
                
                # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªï¼ˆé¦¬åãŒç›´æ¥ã‚­ãƒ¼ã«ãªã£ã¦ã„ã‚‹ï¼‰
                if isinstance(data, dict) and 'horses' not in data:
                    horse_count = len(data)
                    logger.info("âœ… åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº† (%sé ­)", horse_count)
                    
                    # horsesã‚­ãƒ¼ã§ãƒ©ãƒƒãƒ—
                    wrapped_data = {
                        "meta": {
                            "version": "2.0",
                            "type": "local_racing",
                            "created_at": datetime.now().isoformat()
                        },
                        "horses": data
                    }
                    
                    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«ä¿å­˜
                    self._write_full_cache(wrapped_data)
                    self._save_sharded_cache(wrapped_data)
                    return wrapped_data
                else:
                    # æ—¢ã«ãƒ©ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹
                    horse_count = len(data.get('horses', {}))
                    logger.info("âœ… åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº† (%sé ­)", horse_count)
                    self._write_full_cache(data)
                    self._save_sharded_cache(data)
                    return data
            else:
                logger.error("âŒ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•— HTTP %s", response.status_code)
        except requests.exceptions.Timeout:
            logger.error("âŒ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (300ç§’)")
        except json.JSONDecodeError as e:
            logger.error("âŒ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ (%s)", e)
        except Exception as e:
            logger.error("âŒ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼ (%s)", e)
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: CDNå–å¾—å¤±æ•—ã®ãŸã‚ç©ºãƒ‡ãƒ¼ã‚¿ã§åˆæœŸåŒ–")
        return {"horses": {}}
    
    def _write_full_cache(self, data: Dict[str, Any]):
        """å…ƒã®å˜ä¸€JSONã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›¸ãå‡ºã—"""
        try:
            os.makedirs(os.path.dirname(self.knowledge_file), exist_ok=True)
            with open(self.knowledge_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False)
            logger.info("ğŸ’¾ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å®Œäº†")
        except Exception as e:
            logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜å¤±æ•— (%s)", e)

    def _shard_filename(self, shard_id: int) -> str:
        return f"shard_{shard_id:05d}.json"

    def _write_shard(self, shard_id: int, shard_data: Dict[str, Any]):
        os.makedirs(self.cache_dir, exist_ok=True)
        shard_path = os.path.join(self.cache_dir, self._shard_filename(shard_id))
        with open(shard_path, 'w', encoding='utf-8') as f:
            json.dump(shard_data, f, ensure_ascii=False)

    def _save_sharded_cache(self, data: Dict[str, Any]):
        horses = data.get('horses', {})
        if not horses:
            return

        os.makedirs(self.cache_dir, exist_ok=True)

        # æ—¢å­˜ã‚·ãƒ£ãƒ¼ãƒ‰ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        for entry in os.listdir(self.cache_dir):
            if entry.endswith('.json'):
                try:
                    os.remove(os.path.join(self.cache_dir, entry))
                except OSError:
                    logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: å¤ã„ã‚·ãƒ£ãƒ¼ãƒ‰å‰Šé™¤ã«å¤±æ•— (%s)", entry)

        index: Dict[str, Dict[str, str]] = {}
        shard_data: Dict[str, Any] = {}
        shard_id = 0
        count = 0

        for horse_name, horse_payload in horses.items():
            if count > 0 and count % self._shard_size == 0:
                self._write_shard(shard_id, shard_data)
                shard_id += 1
                shard_data = {}
            shard_data[horse_name] = horse_payload
            index[horse_name] = {"file": self._shard_filename(shard_id)}
            count += 1

        if shard_data:
            self._write_shard(shard_id, shard_data)

        index_content = {
            "meta": data.get('meta', {}),
            "generated_at": datetime.now().isoformat(),
            "shard_count": shard_id + 1,
            "horses": index
        }

        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(index_content, f, ensure_ascii=False)

        self._horse_index = index
        self._meta_info = index_content.get('meta', {})

    def _load_index(self) -> bool:
        if not os.path.exists(self.index_file):
            return False
        try:
            with open(self.index_file, 'r', encoding='utf-8') as f:
                index_data = json.load(f)
            horses = index_data.get('horses', {})
            if not horses:
                return False
            self._horse_index = horses
            self._meta_info = index_data.get('meta', {})
            logger.info("ğŸ“‚ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼ (%sé ­)", len(self._horse_index))
            return True
        except Exception as e:
            logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‰ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­è¾¼å¤±æ•— (%s)", e)
            return False

    def _load_shard(self, shard_file: str) -> Dict[str, Any]:
        with self._shard_lock:
            if shard_file in self._shard_cache:
                # LRU æ›´æ–°
                self._shard_cache.move_to_end(shard_file)
                return self._shard_cache[shard_file]

            shard_path = os.path.join(self.cache_dir, shard_file)
            try:
                with open(shard_path, 'r', encoding='utf-8') as f:
                    shard_data = json.load(f)
            except FileNotFoundError:
                logger.warning("âš ï¸ åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‰ %s ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†æ§‹ç¯‰ã‚’è©¦ã¿ã¾ã™", shard_file)
                self._knowledge_data = None
                self._horse_index = {}
                self._meta_info = {}
                self._shard_cache.clear()
                if os.path.exists(self.knowledge_file):
                    data = self._load_knowledge()
                    self._knowledge_data = data
                    self._last_loaded_at = datetime.now()
                    if not self._horse_index:
                        self._load_index()
                    return self._load_shard(shard_file)
                raise

            self._shard_cache[shard_file] = shard_data
            self._shard_cache.move_to_end(shard_file)
            if len(self._shard_cache) > self._max_shard_cache:
                self._shard_cache.popitem(last=False)

            return shard_data

    def _get_horse_entry(self, horse_name: str) -> Optional[Dict[str, Any]]:
        self._ensure_loaded()
        if self._knowledge_data is not None:
            return self._knowledge_data.get('horses', {}).get(horse_name)

        shard_info = self._horse_index.get(horse_name)
        if not shard_info:
            return None

        shard_file = shard_info.get('file')
        if not shard_file:
            return None

        shard_data = self._load_shard(shard_file)
        return shard_data.get(horse_name)

    def _ensure_loaded(self):
        if self._knowledge_data is not None:
            return

        with self._load_lock:
            if self._knowledge_data is not None:
                return

            if self._load_index():
                self._last_loaded_at = datetime.now()
                logger.info("âœ… åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ã¿ãƒ­ãƒ¼ãƒ‰å®Œäº† (%sé ­)", len(self._horse_index))
                return

            data = self._load_knowledge()
            self._knowledge_data = data
            self._last_loaded_at = datetime.now()

            horse_count = len(data.get('horses', {}))
            logger.info("âœ… åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ãƒ•ãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰å®Œäº† (%sé ­)", horse_count)

            if not self._horse_index:
                self._load_index()

    @property
    def knowledge_data(self) -> Dict[str, Any]:
        self._ensure_loaded()

        if self._knowledge_data is None and self._horse_index:
            logger.debug("åœ°æ–¹ç«¶é¦¬ãƒŠãƒ¬ãƒƒã‚¸: ã‚·ãƒ£ãƒ¼ãƒ‰ã‹ã‚‰ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªãƒ‡ãƒ¼ã‚¿ã‚’çµ„ã¿ç«‹ã¦ã¦ã„ã¾ã™ (ä¸€æ™‚çš„ã«é‡ã„å‡¦ç†)")
            horses: Dict[str, Any] = {}
            loaded_files = set()
            for info in self._horse_index.values():
                shard_file = info.get('file')
                if not shard_file or shard_file in loaded_files:
                    continue
                shard_data = self._load_shard(shard_file)
                horses.update(shard_data)
                loaded_files.add(shard_file)

            self._knowledge_data = {
                "meta": self._meta_info,
                "horses": horses
            }

        return self._knowledge_data or {"horses": {}}
    
    def get_raw_horse_data(self, horse_name: str) -> Optional[Dict[str, Any]]:
        """é¦¬ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        races = self._get_horse_entry(horse_name)
        if races is None:
            return None
        
        # åœ°æ–¹ç«¶é¦¬ç‰ˆã¯é…åˆ—å½¢å¼ãªã®ã§ã€JRAç‰ˆã¨åŒã˜å½¢å¼ã«å¤‰æ›
        if isinstance(races, list):
            return {
                "horse_name": horse_name,
                "races": races,
                "race_count": len(races)
            }
        # æ—¢ã«JRAå½¢å¼ã®å ´åˆã¯ãã®ã¾ã¾è¿”ã™
        return races
    
    def get_horse_raw_data(self, horse_name: str) -> Optional[Dict[str, Any]]:
        """é¦¬ã®ç”Ÿãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆäº’æ›æ€§ã®ãŸã‚åˆ¥åã‚‚æä¾›ï¼‰"""
        return self.get_raw_horse_data(horse_name)
    
    def get_all_horse_names(self) -> list:
        """å…¨é¦¬åãƒªã‚¹ãƒˆã‚’å–å¾—"""
        if self._horse_index:
            return list(self._horse_index.keys())
        return list(self.knowledge_data.get('horses', {}).keys())
    
    def get_horse_data(self, horse_name: str) -> Optional[Dict[str, Any]]:
        """é¦¬ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆViewLogicã¨ã®äº’æ›æ€§ã®ãŸã‚ï¼‰"""
        return self.get_horse_raw_data(horse_name)
    
    def is_loaded(self) -> bool:
        """ãƒ‡ãƒ¼ã‚¿ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
        if self._knowledge_data is not None:
            return bool(self._knowledge_data.get('horses'))
        return bool(self._horse_index)
    
    def calculate_dlogic_realtime(self, horse_name: str) -> Dict[str, Any]:
        """ç”Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ D-Logicè¨ˆç®—ï¼ˆãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥å¯¾å¿œï¼‰"""
        # ãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        with self._cache_lock:
            cached = self._calculation_cache.get(horse_name)
            if cached is not None:
                self._cache_hits += 1
                total_requests = self._cache_hits + self._cache_misses
                if total_requests % self._cache_log_interval == 0:
                    hit_rate = (self._cache_hits / total_requests) * 100 if total_requests else 0.0
                    logger.info(
                        "ğŸ“Š åœ°æ–¹D-Logicã‚­ãƒ£ãƒƒã‚·ãƒ¥: hit=%s miss=%s hit_rate=%.1f%%", 
                        self._cache_hits,
                        self._cache_misses,
                        hit_rate
                    )
                return cached

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹æ™‚ã®å‡¦ç†
        self._cache_misses += 1

        raw_data = self.get_horse_raw_data(horse_name)
        if not raw_data:
            return {
                "horse_name": horse_name,
                "total_score": -1,  # ãƒ‡ãƒ¼ã‚¿ä¸è¶³ãƒãƒ¼ã‚«ãƒ¼
                "error": f"{horse_name}ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“",
                "data_available": False
            }
        
        # 12é …ç›®ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¨ˆç®—
        scores = {
            "1_distance_aptitude": self._calc_distance_aptitude(raw_data),
            "2_bloodline_evaluation": self._calc_bloodline_evaluation(raw_data),
            "3_jockey_compatibility": self._calc_jockey_compatibility(raw_data),
            "4_trainer_evaluation": self._calc_trainer_evaluation(raw_data),
            "5_track_aptitude": self._calc_track_aptitude(raw_data),
            "6_weather_aptitude": self._calc_weather_aptitude(raw_data),
            "7_popularity_factor": self._calc_popularity_factor(raw_data),
            "8_weight_impact": self._calc_weight_impact(raw_data),
            "9_horse_weight_impact": self._calc_horse_weight_impact(raw_data),
            "10_corner_specialist_degree": self._calc_corner_specialist(raw_data),
            "11_margin_analysis": self._calc_margin_analysis(raw_data),
            "12_time_index": self._calc_time_index(raw_data)
        }
        
        # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯åŸºæº–ï¼‰
        total_score = self._calculate_total_score(scores)

        result = {
            "horse_name": horse_name,
            "d_logic_scores": scores,
            "total_score": total_score,
            "grade": self._grade_performance(total_score),
            "data_available": True,
            "calculation_time": datetime.now().isoformat()
        }

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«æ ¼ç´
        if self._max_cache_size > 0:
            with self._cache_lock:
                if len(self._calculation_cache) >= self._max_cache_size:
                    # æœ€ã‚‚å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆFIFOï¼‰
                    first_key = next(iter(self._calculation_cache), None)
                    if first_key is not None:
                        self._calculation_cache.pop(first_key, None)
                self._calculation_cache[horse_name] = result

        return result

    def get_cache_stats(self) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆã‚’è¿”ã™"""
        total_requests = self._cache_hits + self._cache_misses
        hit_rate = (self._cache_hits / total_requests) * 100 if total_requests else 0.0
        return {
            "hits": self._cache_hits,
            "misses": self._cache_misses,
            "requests": total_requests,
            "hit_rate": round(hit_rate, 2),
            "cache_size": len(self._calculation_cache),
            "max_cache_size": self._max_cache_size,
            "last_loaded_at": self._last_loaded_at.isoformat() if self._last_loaded_at else None
        }

    def clear_calculation_cache(self):
        """è¨ˆç®—ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢"""
        with self._cache_lock:
            self._calculation_cache.clear()
            self._cache_hits = 0
            self._cache_misses = 0

    def _calc_distance_aptitude(self, raw_data: Dict) -> float:
        """è·é›¢é©æ€§è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        if not races:
            return 50.0
        
        # è·é›¢åˆ¥æˆç¸¾ã‚’é›†è¨ˆ
        distance_perf = {}
        for race in races:
            distance = race.get("KYORI") or race.get("distance")
            finish = race.get("KAKUTEI_CHAKUJUN") or race.get("finish")
            if distance and finish:
                if distance not in distance_perf:
                    distance_perf[distance] = []
                try:
                    distance_perf[distance].append(int(finish))
                except (ValueError, TypeError):
                    continue
        
        if not distance_perf:
            return 50.0
        
        # å¹³å‡ç€é †ã‹ã‚‰é©æ€§ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—
        best_score = 0
        for distance, finishes in distance_perf.items():
            avg_finish = sum(finishes) / len(finishes)
            score = max(0, 100 - (avg_finish - 1) * 10)
            best_score = max(best_score, score)
        
        return min(100, best_score)
    
    def _calc_bloodline_evaluation(self, raw_data: Dict) -> float:
        """è¡€çµ±è©•ä¾¡è¨ˆç®—"""
        stats = raw_data.get("aggregated_stats", {})
        wins = stats.get("wins", 0)
        total = stats.get("total_races", 0)
        
        if total == 0:
            races = raw_data.get("races", raw_data.get("race_history", []))
            if races:
                total = len(races)
                wins = sum(1 for race in races if str(race.get("KAKUTEI_CHAKUJUN", race.get("finish", "99"))).strip() == "01" or race.get("KAKUTEI_CHAKUJUN", race.get("finish", 99)) == 1)
        
        win_rate = wins / total if total > 0 else 0
        return min(100, win_rate * 200)
    
    def _calc_jockey_compatibility(self, raw_data: Dict) -> float:
        """é¨æ‰‹ç›¸æ€§è¨ˆç®—"""
        jockey_perf = raw_data.get("aggregated_stats", {}).get("jockey_performance", {})
        
        if not jockey_perf:
            races = raw_data.get("races", raw_data.get("race_history", []))
            if races:
                jockey_perf = {}
                for race in races:
                    jockey = race.get("KISHUMEI_RYAKUSHO", race.get("KISYURYAKUSYO", race.get("jockey", "")))
                    finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish"))
                    if jockey and finish:
                        if jockey not in jockey_perf:
                            jockey_perf[jockey] = []
                        try:
                            jockey_perf[jockey].append(int(finish))
                        except (ValueError, TypeError):
                            continue
        
        if not jockey_perf:
            return 50.0
        
        best_avg = 999
        for jockey, finishes in jockey_perf.items():
            if len(finishes) >= 1:
                avg = sum(finishes) / len(finishes)
                best_avg = min(best_avg, avg)
        
        if best_avg == 999:
            return 50.0
        
        return max(0, min(100, 100 - (best_avg - 1) * 10))
    
    def _calc_trainer_evaluation(self, raw_data: Dict) -> float:
        """èª¿æ•™å¸«è©•ä¾¡è¨ˆç®—"""
        trainer_perf = raw_data.get("aggregated_stats", {}).get("trainer_performance", {})
        
        if not trainer_perf:
            races = raw_data.get("races", raw_data.get("race_history", []))
            if races:
                trainer_perf = {}
                for race in races:
                    trainer = race.get("CHOKYOSHIMEI_RYAKUSHO", race.get("CHOUKYOUSIRYAKUSYO", race.get("trainer", "")))
                    finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish"))
                    if trainer and finish:
                        if trainer not in trainer_perf:
                            trainer_perf[trainer] = []
                        try:
                            trainer_perf[trainer].append(int(finish))
                        except (ValueError, TypeError):
                            continue
        
        if not trainer_perf:
            return 50.0
        
        best_avg = 999
        for trainer, finishes in trainer_perf.items():
            if len(finishes) >= 1:
                avg = sum(finishes) / len(finishes)
                best_avg = min(best_avg, avg)
        
        if best_avg == 999:
            return 50.0
        
        return max(0, min(100, 100 - (best_avg - 1) * 10))
    
    def _calc_track_aptitude(self, raw_data: Dict) -> float:
        """ãƒˆãƒ©ãƒƒã‚¯é©æ€§è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        track_perf = {}
        
        for race in races:
            track_code = race.get("TRACK_CODE", race.get("TRACKCD", race.get("track", "")))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish"))
            
            if track_code and finish:
                if track_code in ["10", "11", "12", "13", "14", "15", "16", "17", "18", "19"]:
                    track = "èŠ"
                elif track_code in ["20", "21", "22", "23", "24", "25", "26", "27", "28", "29"]:
                    track = "ãƒ€ãƒ¼ãƒˆ"
                else:
                    track = str(track_code)
                
                if track not in track_perf:
                    track_perf[track] = []
                try:
                    track_perf[track].append(int(finish))
                except (ValueError, TypeError):
                    continue
        
        if not track_perf:
            return 50.0
        
        best_score = 0
        for track, finishes in track_perf.items():
            avg_finish = sum(finishes) / len(finishes)
            score = max(0, 100 - (avg_finish - 1) * 10)
            best_score = max(best_score, score)
        
        return min(100, best_score)
    
    def _calc_weather_aptitude(self, raw_data: Dict) -> float:
        """å¤©å€™é©æ€§è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        if not races:
            return 50.0
        
        weather_perf = {}
        
        for race in races:
            tenko = race.get("TENKO_CODE", race.get("weather", 0))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            track_code = race.get("TRACK_CODE", "")
            
            if str(track_code).startswith("1"):  # èŠ
                baba = race.get("SHIBA_BABAJOTAI_CODE", 1)
            else:  # ãƒ€ãƒ¼ãƒˆ
                baba = race.get("DIRT_BABAJOTAI_CODE", 1)
            
            if tenko and finish:
                weather_key = f"{tenko}_{baba}"
                if weather_key not in weather_perf:
                    weather_perf[weather_key] = []
                try:
                    weather_perf[weather_key].append(int(finish))
                except (ValueError, TypeError):
                    continue
        
        if not weather_perf:
            return 50.0
        
        total_races = sum(len(finishes) for finishes in weather_perf.values())
        weighted_score = 0
        
        for weather_key, finishes in weather_perf.items():
            avg_finish = sum(finishes) / len(finishes)
            score = max(0, 100 - (avg_finish - 1) * 10)
            weight = len(finishes) / total_races
            weighted_score += score * weight
        
        return min(100, weighted_score)
    
    def _calc_popularity_factor(self, raw_data: Dict) -> float:
        """äººæ°—åº¦è¦å› è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        if not races:
            return 50.0
        
        performance_scores = []
        for race in races:
            popularity = race.get("TANSHO_NINKIJUN", race.get("NINKIJUN", race.get("popularity", 0)))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            
            if popularity and finish:
                try:
                    pop_int = int(popularity)
                    fin_int = int(finish)
                    
                    if pop_int <= fin_int:
                        score = 100 - (fin_int - pop_int) * 10
                    else:
                        score = 100 - (pop_int - fin_int) * 5
                    
                    performance_scores.append(max(0, min(100, score)))
                except (ValueError, TypeError):
                    continue
        
        if not performance_scores:
            return 50.0
        
        return sum(performance_scores) / len(performance_scores)
    
    def _calc_weight_impact(self, raw_data: Dict) -> float:
        """é‡é‡å½±éŸ¿åº¦è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        weight_scores = []
        
        for race in races:
            weight = race.get("FUTAN_JURYO", race.get("FUTAN", race.get("weight", 0)))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            
            if weight and finish:
                try:
                    weight_int = int(weight)
                    finish_int = int(finish)
                    
                    weight_score = max(0, 100 - abs(weight_int - 550) / 10 * 5)
                    
                    if finish_int <= 3:
                        weight_score *= 1.1
                    
                    weight_scores.append(min(100, weight_score))
                except (ValueError, TypeError):
                    continue
        
        return sum(weight_scores) / len(weight_scores) if weight_scores else 50.0
    
    def _calc_horse_weight_impact(self, raw_data: Dict) -> float:
        """é¦¬ä½“é‡å½±éŸ¿åº¦è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        weight_scores = []
        
        for race in races:
            horse_weight = race.get("BATAIJU", race.get("BATAI", race.get("horse_weight", 0)))
            weight_change = race.get("ZOGEN_SA", race.get("ZOUGEN", race.get("weight_change", 0)))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            
            if horse_weight and finish:
                try:
                    weight_int = int(horse_weight)
                    finish_int = int(finish)
                    change_int = int(weight_change) if weight_change else 0
                    
                    base_score = 75
                    if 460 <= weight_int <= 500:
                        base_score = 100
                    elif weight_int < 440 or weight_int > 520:
                        base_score = 50
                    
                    if abs(change_int) > 10:
                        base_score *= 0.9
                    
                    weight_scores.append(base_score)
                except (ValueError, TypeError):
                    continue
        
        return sum(weight_scores) / len(weight_scores) if weight_scores else 50.0
    
    def _calc_corner_specialist(self, raw_data: Dict) -> float:
        """ã‚³ãƒ¼ãƒŠãƒ¼å°‚é–€åº¦è¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        improvements = []
        
        for race in races:
            corner1 = race.get("CORNER1_JUNI", race.get("CORNER1JUN", race.get("corner1", 0)))
            corner2 = race.get("CORNER2_JUNI", race.get("CORNER2JUN", race.get("corner2", 0)))
            corner3 = race.get("CORNER3_JUNI", race.get("CORNER3JUN", race.get("corner3", 0)))
            corner4 = race.get("CORNER4_JUNI", race.get("CORNER4JUN", race.get("corner4", 0)))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            
            if finish:
                try:
                    finish_int = int(finish)
                    corners = [c for c in [corner1, corner2, corner3, corner4] if c]
                    
                    if corners:
                        last_corner = int(corners[-1])
                        improvement = last_corner - finish_int
                        
                        if improvement > 0:
                            score = 50 + improvement * 10
                        else:
                            score = 50 + improvement * 5
                        
                        improvements.append(max(0, min(100, score)))
                except (ValueError, TypeError):
                    continue
        
        return sum(improvements) / len(improvements) if improvements else 50.0
    
    def _calc_margin_analysis(self, raw_data: Dict) -> float:
        """ç€å·®åˆ†æè¨ˆç®—"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        finish_scores = []
        
        for race in races:
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            margin = race.get("CHAKUSA", race.get("margin", ""))
            
            if finish:
                try:
                    finish_int = int(finish)
                    base_score = max(0, 100 - (finish_int - 1) * 6)
                    
                    if finish_int == 1 and margin:
                        try:
                            if "å¤§å·®" in str(margin):
                                base_score = 100
                            elif margin and float(margin) >= 0.5:
                                base_score = min(100, base_score * 1.1)
                        except:
                            pass
                    
                    finish_scores.append(base_score)
                except (ValueError, TypeError):
                    continue
        
        return sum(finish_scores) / len(finish_scores) if finish_scores else 50.0
    
    def _calc_time_index(self, raw_data: Dict) -> float:
        """ã‚¿ã‚¤ãƒ æŒ‡æ•°è¨ˆç®—ï¼ˆç°¡ç•¥ç‰ˆï¼‰"""
        races = raw_data.get("races", raw_data.get("race_history", []))
        time_scores = []
        
        for race in races:
            time = race.get("SOHA_TIME", race.get("TIME", race.get("time", 0)))
            finish = race.get("KAKUTEI_CHAKUJUN", race.get("finish", 0))
            distance = race.get("KYORI", race.get("distance", 0))
            
            if time and finish and distance:
                try:
                    time_float = float(time) / 10.0 if time else 0
                    finish_int = int(finish)
                    distance_int = int(distance)
                    
                    if time_float > 0 and distance_int > 0:
                        speed = distance_int / time_float
                        
                        base_score = 50
                        if speed > 16:
                            base_score = 90
                        elif speed > 15:
                            base_score = 75
                        elif speed > 14:
                            base_score = 60
                        
                        if finish_int <= 3:
                            base_score = min(100, base_score * 1.1)
                        
                        time_scores.append(base_score)
                except (ValueError, TypeError):
                    continue
        
        return sum(time_scores) / len(time_scores) if time_scores else 50.0
    
    def _calculate_total_score(self, scores: Dict[str, float]) -> float:
        """ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆãƒ€ãƒ³ã‚¹ã‚¤ãƒ³ã‚¶ãƒ€ãƒ¼ã‚¯åŸºæº–ï¼‰"""
        weights = [1.2, 1.1, 1.0, 1.0, 1.1, 0.9, 0.8, 0.9, 0.8, 1.0, 1.1, 1.2]
        
        ordered_keys = [
            "1_distance_aptitude",
            "2_bloodline_evaluation", 
            "3_jockey_compatibility",
            "4_trainer_evaluation",
            "5_track_aptitude",
            "6_weather_aptitude",
            "7_popularity_factor",
            "8_weight_impact",
            "9_horse_weight_impact",
            "10_corner_specialist_degree",
            "11_margin_analysis",
            "12_time_index"
        ]
        
        total_weighted_score = 0
        total_weight = 0
        
        for i, key in enumerate(ordered_keys):
            if key in scores:
                total_weighted_score += scores[key] * weights[i]
                total_weight += weights[i]
        
        if total_weight == 0:
            return 50.0
        
        return total_weighted_score / total_weight
    
    def _grade_performance(self, score: float) -> str:
        """æˆç¸¾ã‚°ãƒ¬ãƒ¼ãƒ‰åˆ¤å®š"""
        if score >= 90:
            return "SS (ä¼èª¬ç´š)"
        elif score >= 80:
            return "S (è¶…ä¸€æµ)"
        elif score >= 70:
            return "A (ä¸€æµ)"
        elif score >= 60:
            return "B (è‰¯é¦¬)"
        elif score >= 50:
            return "C (å¹³å‡)"
        else:
            return "D (è¦æ”¹å–„)"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰
local_dlogic_manager_v2 = LocalDLogicRawDataManagerV2()
logger.info("ğŸ‡ åœ°æ–¹ç«¶é¦¬ç‰ˆD-Logicãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼V2æº–å‚™å®Œäº†")
