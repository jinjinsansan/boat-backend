"""
ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ãƒ¬ãƒ¼ã‚¹æ¤œç´¢ãƒãƒ³ãƒ‰ãƒ©ãƒ¼
TSãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé«˜é€Ÿï¼‰ã¨Supabaseï¼ˆæ‹¡å¼µæ€§ï¼‰ã®ä¸¡æ–¹ã‹ã‚‰æ¤œç´¢
"""
import re
import logging
from typing import Optional, Dict, Any, List
from datetime import datetime, date, timedelta
from services.archive_race_handler import archive_race_handler
from services.supabase_client import supabase_client
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

class HybridArchiveHandler:
    """TSãƒ•ã‚¡ã‚¤ãƒ«ã¨Supabaseã®ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢"""
    
    def __init__(self):
        self.frontend_base_url = "https://www.dlogicai.in"
        self.base_handler = archive_race_handler
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆãƒ¡ãƒ¢ãƒªå†…ã§é »ç¹ã«ã‚¢ã‚¯ã‚»ã‚¹ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼‰
        self._cache: Dict[str, Dict[str, Any]] = {}
        self._cache_ttl = 300  # 5åˆ†é–“ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        
        # æœ€æ–°5æ—¥é–“ã®æ—¥ä»˜ï¼ˆTSãƒ•ã‚¡ã‚¤ãƒ«ã§ç®¡ç†ã•ã‚Œã‚‹æƒ³å®šï¼‰
        self._recent_dates = self._get_recent_dates()
    
    def _get_recent_dates(self) -> List[str]:
        """æœ€æ–°5æ—¥é–“ã®æ—¥ä»˜ã‚’å–å¾—ï¼ˆæœªæ¥2æ—¥+éå»3æ—¥ï¼‰"""
        today = date.today()
        dates = []
        
        # æœªæ¥ã®2æ—¥é–“
        for i in range(2, 0, -1):
            future_date = today + timedelta(days=i)
            dates.append(future_date.strftime("%Y-%m-%d"))
        
        # ä»Šæ—¥
        dates.append(today.strftime("%Y-%m-%d"))
        
        # éå»ã®2æ—¥é–“
        for i in range(1, 3):
            past_date = today - timedelta(days=i)
            dates.append(past_date.strftime("%Y-%m-%d"))
        
        return dates
    
    def extract_race_info(self, message: str) -> Optional[Dict[str, Any]]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰ãƒ¬ãƒ¼ã‚¹æƒ…å ±ã‚’æŠ½å‡º"""
        return self.base_handler.extract_race_info(message)
    
    def extract_specific_date(self, message: str) -> Optional[str]:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰å…·ä½“çš„ãªæ—¥ä»˜ã‚’æŠ½å‡º"""
        patterns = [
            r'(\d{1,2})æœˆ(\d{1,2})æ—¥',
            r'(\d{1,2})/(\d{1,2})',
            r'(\d{4})-(\d{2})-(\d{2})',
            r'(\d{4})å¹´(\d{1,2})æœˆ(\d{1,2})æ—¥'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, message)
            if match:
                groups = match.groups()
                if len(groups) == 2:
                    month, day = int(groups[0]), int(groups[1])
                    year = datetime.now().year
                    try:
                        date_obj = date(year, month, day)
                        return date_obj.strftime("%Y-%m-%d")
                    except ValueError:
                        continue
                elif len(groups) == 3:
                    try:
                        if len(groups[0]) == 4:
                            year, month, day = int(groups[0]), int(groups[1]), int(groups[2])
                        else:
                            year, month, day = int(groups[0]), int(groups[1]), int(groups[2])
                        date_obj = date(year, month, day)
                        return date_obj.strftime("%Y-%m-%d")
                    except ValueError:
                        continue
        
        return None
    
    async def search_archive_races_with_priority(self, race_info: Dict[str, Any], current_date: Optional[str] = None) -> Dict[str, Any]:
        """
        ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ï¼šTSãƒ•ã‚¡ã‚¤ãƒ«å„ªå…ˆã€ä¸è¶³åˆ†ã‚’Supabaseã‹ã‚‰å–å¾—
        """
        if not current_date:
            current_date = datetime.now().strftime("%Y-%m-%d")
        
        venue = race_info.get("venue")
        race_number = race_info.get("race_number")
        specific_date = race_info.get("date")
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        cache_key = f"{venue}_{race_number}_{specific_date or 'all'}"
        if cache_key in self._cache:
            cached_data = self._cache[cache_key]
            if datetime.now().timestamp() - cached_data['timestamp'] < self._cache_ttl:
                logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆ: {cache_key}")
                return cached_data['data']
        
        # ç‰¹å®šã®æ—¥ä»˜ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ
        if specific_date:
            # æœ€è¿‘ã®æ—¥ä»˜ãªã‚‰TSãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰å–å¾—
            if specific_date in self._recent_dates:
                result = await self._search_from_frontend(venue, race_number, specific_date)
                if result['found']:
                    return result
            
            # Supabaseã‹ã‚‰å–å¾—
            result = await self._search_from_supabase(venue, race_number, specific_date)
            if result['found']:
                self._update_cache(cache_key, result)
                return result
            
            return {"found": False, "matches": []}
        
        # æ—¥ä»˜æŒ‡å®šãªã—ã®å ´åˆï¼šãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢
        all_matches = []
        
        # 1. TSãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ€æ–°5ä»¶ã‚’æ¤œç´¢ï¼ˆè¶…é«˜é€Ÿï¼‰
        frontend_task = asyncio.create_task(self._search_recent_from_frontend(venue, race_number))
        
        # 2. 5ä»¶è¦‹ã¤ã‹ã£ãŸã‚‰å³è¿”å´
        frontend_result = await frontend_task
        if frontend_result['found'] and len(frontend_result['matches']) >= 5:
            logger.info(f"TSãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã§5ä»¶å–å¾—å®Œäº†")
            result = self._format_with_priority(frontend_result['matches'][:5], current_date)
            self._update_cache(cache_key, result)
            return result
        
        # 3. ä¸è¶³åˆ†ã‚’Supabaseã‹ã‚‰å–å¾—
        needed_count = 5 - len(frontend_result.get('matches', []))
        if needed_count > 0:
            supabase_result = await self._search_from_supabase(
                venue, race_number, None, limit=needed_count,
                exclude_dates=self._recent_dates
            )
            
            # çµæœã‚’ãƒãƒ¼ã‚¸
            all_matches = frontend_result.get('matches', []) + supabase_result.get('matches', [])
        else:
            all_matches = frontend_result.get('matches', [])
        
        # å„ªå…ˆé †ä½ä»˜ã‘ã—ã¦è¿”å´
        result = self._format_with_priority(all_matches[:5], current_date)
        self._update_cache(cache_key, result)
        return result
    
    async def _search_recent_from_frontend(self, venue: str, race_number: int) -> Dict[str, Any]:
        """æœ€è¿‘ã®æ—¥ä»˜ã®TSãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ¤œç´¢"""
        from services.frontend_archive_client import frontend_archive_client
        
        matches = []
        
        # ä¸¦åˆ—æ¤œç´¢ã®ãŸã‚ã®ã‚¿ã‚¹ã‚¯
        tasks = []
        for date_str in self._recent_dates:
            task = frontend_archive_client.search_archive_races(venue, race_number, date_str)
            tasks.append(task)
        
        # ã™ã¹ã¦ã®ã‚¿ã‚¹ã‚¯ã‚’ä¸¦åˆ—å®Ÿè¡Œ
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {result}")
                continue
            
            if result.get('found') and result.get('races'):
                matches.extend(result['races'])
        
        return {
            "found": len(matches) > 0,
            "matches": matches
        }
    
    async def _search_from_frontend(self, venue: str, race_number: int, specific_date: str) -> Dict[str, Any]:
        """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰APIã‹ã‚‰æ¤œç´¢"""
        from services.frontend_archive_client import frontend_archive_client
        
        try:
            result = await frontend_archive_client.search_archive_races(venue, race_number, specific_date)
            if result.get('found'):
                return {
                    "found": True,
                    "matches": result.get('races', [])
                }
        except Exception as e:
            logger.error(f"ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        return {"found": False, "matches": []}
    
    async def _search_from_supabase(self, venue: str, race_number: int, 
                                   specific_date: Optional[str] = None,
                                   limit: int = 5,
                                   exclude_dates: Optional[List[str]] = None) -> Dict[str, Any]:
        """Supabaseã‹ã‚‰æ¤œç´¢"""
        if not supabase_client.is_available():
            logger.warning("Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            return {"found": False, "matches": []}
        
        try:
            # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
            query = supabase_client.client.table('archive_races') \
                .select('*') \
                .eq('venue', venue) \
                .eq('race_number', race_number)
            
            if specific_date:
                query = query.eq('race_date', specific_date)
            else:
                # é™¤å¤–ã™ã‚‹æ—¥ä»˜ãŒã‚ã‚‹å ´åˆ
                if exclude_dates:
                    for date_str in exclude_dates:
                        query = query.neq('race_date', date_str)
                
                # æ–°ã—ã„é †ã«ã‚½ãƒ¼ãƒˆ
                query = query.order('race_date', desc=True).limit(limit)
            
            # å®Ÿè¡Œ
            response = query.execute()
            
            if response.data:
                matches = []
                for race in response.data:
                    match = {
                        "date": race['race_date'],
                        "venue": race['venue'],
                        "race_number": race['race_number'],
                        "race_name": race['race_name'],
                        "archive_url": f"/archive/{race['race_date']}",
                        "has_jockey_data": bool(race.get('jockeys')),
                        "grade": race.get('grade', ''),
                        "horses": race.get('horses', []),
                        "jockeys": race.get('jockeys'),
                        "posts": race.get('posts'),
                        "horse_numbers": race.get('horse_numbers'),
                        "distance": race.get('distance'),
                        "track_condition": race.get('track_condition', 'è‰¯')
                    }
                    matches.append(match)
                
                return {
                    "found": True,
                    "matches": matches
                }
            
        except Exception as e:
            logger.error(f"Supabaseæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
        
        return {"found": False, "matches": []}
    
    def _format_with_priority(self, matches: List[Dict[str, Any]], current_date: str) -> Dict[str, Any]:
        """æ—¥ä»˜å„ªå…ˆé †ä½ã‚’ä»˜ã‘ã¦ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        current_date_obj = datetime.strptime(current_date, "%Y-%m-%d")
        
        matches_with_priority = []
        for match in matches:
            match_date = datetime.strptime(match["date"], "%Y-%m-%d")
            days_diff = (match_date - current_date_obj).days
            
            match_with_priority = match.copy()
            match_with_priority["is_future"] = days_diff > 0
            match_with_priority["days_diff"] = days_diff
            
            weekday_names = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"]
            match_with_priority["weekday"] = weekday_names[match_date.weekday()]
            
            matches_with_priority.append(match_with_priority)
        
        # ã‚½ãƒ¼ãƒˆ: æœªæ¥å„ªå…ˆã€ãã®å¾Œæ–°ã—ã„é †
        matches_with_priority.sort(key=lambda x: (
            not x["is_future"],
            -x["days_diff"] if x["is_future"] else x["days_diff"]
        ))
        
        # æœ€å¤§5ä»¶ã«åˆ¶é™
        limited_matches = matches_with_priority[:5]
        
        return {
            "found": True,
            "matches": limited_matches,
            "count": len(matches),
            "limited_count": len(limited_matches),
            "need_selection": len(limited_matches) > 1,
            "has_more": len(matches) > 5
        }
    
    def _update_cache(self, key: str, data: Dict[str, Any]):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æ›´æ–°"""
        self._cache[key] = {
            'timestamp': datetime.now().timestamp(),
            'data': data
        }
    
    def format_selection_message_with_priority(self, matches: List[Dict[str, Any]], has_more: bool = False) -> str:
        """å„ªå…ˆé †ä½ä»˜ãã®é¸æŠãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ç”Ÿæˆ"""
        if not matches:
            return "è©²å½“ã™ã‚‹ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        
        if len(matches) == 1:
            match = matches[0]
            return f"ğŸ“… {match['date']} {match['venue']}{match['race_number']}Rã€Œ{match['race_name']}ã€ã‚’åˆ†æã—ã¾ã™ã€‚"
        
        message = "è¤‡æ•°ã®ãƒ¬ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚ã©ã¡ã‚‰ã‚’åˆ†æã—ã¾ã™ã‹ï¼Ÿ\n\n"
        
        for i, match in enumerate(matches, 1):
            future_mark = "ï¼ˆæœªæ¥ã®ãƒ¬ãƒ¼ã‚¹ï¼‰" if match.get("is_future", False) else ""
            weekday = f"ï¼ˆ{match.get('weekday', '')}æ›œæ—¥ï¼‰" if match.get('weekday') else ""
            
            grade_badge = ""
            if match.get("grade") == "G1":
                grade_badge = "ğŸ† "
            elif match.get("grade") == "G2":
                grade_badge = "ğŸ¥ˆ "
            elif match.get("grade") == "G3":
                grade_badge = "ğŸ¥‰ "
            
            message += f"{i}. ğŸ“… {match['date']} {match['venue']}{match['race_number']}Rã€Œ{grade_badge}{match['race_name']}ã€{weekday}{future_mark}\n"
        
        message += "\nç•ªå·ã‚’é¸æŠã™ã‚‹ã‹ã€"
        
        if has_more:
            message += "ä¸Šè¨˜ä»¥å¤–ã®æ—¥ä»˜ã‚’ã”å¸Œæœ›ã®å ´åˆã¯ã€æ—¥ä»˜ã‚’ç›´æ¥å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼š7æœˆ20æ—¥ï¼‰ã€‚"
        else:
            message += "ã‚ˆã‚Šè©³ã—ã„æƒ…å ±ï¼ˆæ—¥ä»˜ãªã©ï¼‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
        
        return message
    
    async def get_race_data(self, date: str, venue: str, race_number: int) -> Optional[Dict[str, Any]]:
        """ç‰¹å®šã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ï¼‰"""
        # æœ€è¿‘ã®æ—¥ä»˜ãªã‚‰ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰
        if date in self._recent_dates:
            from services.frontend_archive_client import frontend_archive_client
            race_data = await frontend_archive_client.get_race_data(date, venue, race_number)
            if race_data:
                return race_data
        
        # Supabaseã‹ã‚‰å–å¾—
        if supabase_client.is_available():
            try:
                response = supabase_client.client.table('archive_races') \
                    .select('*') \
                    .eq('race_date', date) \
                    .eq('venue', venue) \
                    .eq('race_number', race_number) \
                    .single() \
                    .execute()
                
                if response.data:
                    race = response.data
                    return {
                        'venue': race['venue'],
                        'race_number': race['race_number'],
                        'race_name': race['race_name'],
                        'grade': race.get('grade', ''),
                        'distance': race.get('distance', ''),
                        'track_condition': race.get('track_condition', 'è‰¯'),
                        'horses': race.get('horses', []),
                        'jockeys': race.get('jockeys', []),
                        'posts': race.get('posts', []),
                        'horse_numbers': race.get('horse_numbers', [])
                    }
            except Exception as e:
                logger.error(f"Supabaseã‹ã‚‰ã®ãƒ¬ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        
        return None

# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
hybrid_archive_handler = HybridArchiveHandler()